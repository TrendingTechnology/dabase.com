# Background

I'm too embarrassed to write this "statistics architecture" up on the
[Webconverger blog](http://r2d2.webconverger.org/2013-01-19/gnuplot-zoom.html)
and this is too technical for [Natalian](http://natalian.org/).

After messing around with [Anselm's monitor rc
scripts](https://github.com/kaihendry/monitor), [fiddling with
GNUplot](https://github.com/kaihendry/laptemp), looking into
[statsd](https://github.com/etsy/statsd) and
[graphite](https://launchpad.net/graphite) (v. scary) and watching [metrics
everywhere](http://pivotallabs.com/139-metrics-metrics-everywhere/)... I have a LOT to think about.

Of course I want to apply the [suckless
philosophy](http://suckless.org/philosophy) and cut through the crap.

# Measure what?

I started with this faux problem of measuring my machine temperature, since
this is related to Webconverger deployments, that require monitoring.
Monitoring translates to business value, since this is what clients are
prepared to pay for.

My "suckless" approach is to generate time series CSV rooted on epoch time.

	*/5 * * * * echo $(date +%s) $(cat /proc/temp) | ssh server 'cat - >> /data/${id:-$SSH_CLIENT}/temp/data.csv'

Over a ssh socket. Then on the server we either run GNUplot over the CSV or
[churn it in JSON](https://github.com/Webconverger/dl/blob/master/toJSON.sh)
and write put the data into a [time series
graph](http://dl.webconverger.com/stats/).

The problem with quirky GNUplot is that the Web output of a PNG or SVG can be
[difficult to
explore](http://r2d2.webconverger.org/2013-01-19/gnuplot-zoom.html) or interact
with. However it's powerful, fast and plays well with shell.

Then again the JSON frontend is easier to write and interact with, but it can
become pretty darn cumbersome.

The CSV files can be probably managed with `logrotate`.

This approach makes a number of assumptions about ssh and the frequency and
such and so forth. And it lacks monitoring **alerts**. I'm not quite sure how
to do that yet. Perhaps extra logic on the server, that filters new data and if
something goes wrong, it sends an alert. My preference would probably be an
email.

# What else should I be measuring?

Important elements for Webconverger are number of subscriptions. Of course this
could be a @daily (instead of every 5 minutes) thing:

	1358518011 45
	1358604429 44

So our generic time series "grapher" script can easily draw this, to show 45
subscribers yesterday and 44 today.

What about something more complicated like, [ping.csv](http://ping.webconverger.org/):

	epoch IP VERSION COUNTRY ID
	1358604429 206.78.148.37 16.0 US ae653a33b312fa3943541f8ac9c9b781

We need to tweak the script that counts things up for a day and then generates
another CSV that filters in a different GNUplot graphing script to generate a
graph.

So on the server we can have we have at its simplest:

	$DATAROOT/$machineid/$graphname/data.csv -> $DATAROOT/$machineid/$graphname.sh -> /srv/www/example.com/stats/$machineid/$graphname.png

`$DATAROOT/*/*/*.csv` is managed by logrotate.

Now with a different "graph script", generic-json.js:

	ln -s generic-json.sh $DATAROOT/$machineid/$graphname.sh

	$DATAROOT/$machineid/$graphname/data.csv -> $DATAROOT/$machineid/$graphname.sh -> /srv/www/example.com/stats/$machineid/$graphname.json -> /srv/www/example.com/stats/$machineid/$graphname/index.{js,css,html}

html/js example: <http://dl.webconverger.com/stats/>

Perhaps we need some filtering / tweaking?

	ln -s special-gnuplot.sh $DATAROOT/$machineid/$graphname.sh

	$DATAROOT/$machineid/$graphname/data.csv -> $DATAROOT/$machineid/$graphname.sh -> /srv/www/example.com/stats/$machineid/$graphname.png

The frequency of how often this generate (i.e. call $graphname.sh) can be
triggered by `inotifywait` on the server. i.e. when it sees new data, it calls
the graphing script.

# Suckless rrdtool

From __20h__ !

## Hierarchy

	$ROOT
	$DATAROOT
	$SCRIPTROOT
	srrd.cron – symlink from /etc/cron.d/srrd
	srrd.logrotate – symlink from /etc/logrotate.d/srrd

$DATAROOT
	$machineid
		$graphname
			csv – csv database
				file-$from-$to.csv
				new.csv
			json – json database
				file-$from-$to.json
				new.js
			png – png database
				png-$from-$to.json
				new.png
			svg – svg database
				svc-$from-$to.svc
				new.svg
			...
	
	$from ::= YYYY[MM[DD[THH[:MM[:SS[.XXXX]]]]]][±ZZZZ]
	$to ::= YYYY[MM[DD[THH[:MM[:SS[.XXXX]]]]]][±ZZZZ]
	$step ::= [[[[[[YYYY]MM]DD]THH:]MM:]SS][.XXXX]

	$step is from the backward, beginning at the smallest time unit up to
	years.

	$from and $to begin at the year and then work towards the
	milliseconds.

	The timezone can be given and will be converted to the internal UTC
	time.

	TODO: Maybe a WXX for week notation could be used too.

$SCRIPTROOT
	csv2all.sh – calls the other csv2 scripts
	csv2json.sh
	csv2png.sh
	csv2svg.sh
	...
	gatherall.sh – runs all gather scripts on the current machine
	gathercpu.sh
	gatherhddtemp.sh
	gathereth0stats.sh
	...

$PATH (system-wide installation)
	srrdc – client application
	srrdr – run script which will run scripts in $SCRIPTROOT

## $SCRIPTROOT calling convention

	csv2all.sh $machineid $graphname

* If $graphname is missing, all $graphname should be generated.
* If $machineid is missing, all $machineid with all $graphname should be
  generated.

## srrdc

	srrdc [options] [[$from] [$to] [$step]]
		-m machineid
		-g graphname
		-f format for output mode [csv,json,png,...]
		-i (input mode)
		-o (output mode)

### Input mode

	cpugatheringscript.sh:

		$timestamp\t$value\n
		$timestamp\t$value\n
		... \
	| -> srrdc -m example -g cpu -i

### Output mode

	srrdc -m example -g cpu -f png -o
		# will output the file 
		# $DATAROOT/example/cpu/png/new.png
	srrdc -m example -g cpu -f json -o 2010 2011 0100T00:00:00 
		# This will generate a json file consisting of all values from
		# 2010 to 2012 in a one month step.

## Input Sources
### Cronjob

* This requires the knowledge of the cron daemon cronjob file. But that is a
  standard around the Linux environment.

	*/10 * * * * /bin/srrdr gathercpu.sh | srrdc -m $MACHINEID -g cpu -i
					   # gather the cpu stats for this
					   # machine

	*/10 * * * * /bin/srrdr csv2all.sh # generate all machines inputting
					   # to this statistics server

### Special Scripts

* Could be using inotifywait.
* See the subsection »Input Mode« of »srrdc«.
