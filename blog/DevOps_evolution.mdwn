Ignoring the complexities surrounding data.

# Phase 1

Manual everything.

Not scalable at all.

# Phase 2

Using a <https://en.wikipedia.org/wiki/Configuration_management> tool like
Chef, Puppet or Ansible.

Scalability achieved with AMI snapshots and such.

# Phase 3

Using PaaS like [Dokku](https://github.com/dokku/dokku), so a developer can
`git push` to a "[Heroku-ish](https://github.com/gliderlabs/herokuish)"
endpoint.

Probably can't scale very well.

# Phase 4

Using Docker & containerizing all the things on something like CoreOS or
RancherOS. Scalability is as manual as making sure you can quickly spin up new
CoreOS instances with a load balancer in front.

Bonus points is if one has figured out how to get a <abbr title="Continuous
Integration">CI</abbr> to build the image and deploy it.

# Phase 5

Orchestrating Docker deployments with [Docker
Compose](https://docs.docker.com/compose/), using things like <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_Console_Repositories.html">AWS <abbr
title="Elastic Container Repository">ECR</abbr> (private Docker image hosting)</a>
and AWS <abbr title="Elastic Container Service">ECS</abbr> for managing the
containers on EC2.

Scales rather well.
